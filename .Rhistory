predict(modFit,trainSA)
predict(modFit,trainSA$chd)
modelFit
missClass(testSA$chd,predict(modelSA,newdata = testSA))
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd,predict(modelSA,newdata = testSA))
missClass(testSA$chd,predict(modelFit
,newdata = testSA))
missClass(trainSA$chd,predict(modelFit
,newdata = trainSA))
library(caret)
library(randomForest)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
modFit<-randomForest(data=vowel.train,y~.)
x<-modFit$importance
class(x)
x<-order(-x)
#x.2, x.1, x.5, x.6, x.8, x.4, x.9, x.3, x.7,x.10
x
library(randomForest)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
modFit<-randomForest(data=vowel.train,y~.)
x<-modFit$importance
class(x)
x
small=prostate[1:5,]
small
lm(lpsa~.,data=small)
x<-data(mtcars)
import(ggplot2)
x<-data(mtcars)
library(ggplot2)
x<-data(mtcars)
p<-ggplot(data=mtcars,x=hp,y=mpg)
p
p<-ggplot(data=mtcars,x=hp,y=mpg) + geom_point()
p
p<-ggplot(data=mtcars,aes(x=hp,y=mpg)) + geom_point()
p
p<-ggplot(data=mtcars,aes(x=cyl,y=mpg)) +
geom_point() +
scale_x_continuous(labels=c("0.5" = "Dose 0.5", "1" = "Dose 1","2" = "Dose 2"))
p
p<-ggplot(data=mtcars,aes(x=cyl,y=mpg)) +
geom_point()
p
p<-ggplot(data=mtcars,aes(x=cyl,y=mpg)) +
geom_point()  +
scale_x_discrete labels(breaks=c("4","6","8"), labels=c("4","6","8"))
p<-ggplot(data=mtcars,aes(x=cyl,y=mpg)) +
geom_point()  +
scale_x_discrete(labels(breaks=c("4","6","8"), labels=c("4","6","8")))
p<-ggplot(data=mtcars,aes(x=cyl,y=mpg)) +
geom_point()  +
scale_x_discrete(labels(breaks=c("4","6","8"), labels=c("4","6","8")))
p
p<-ggplot(data=mtcars,aes(x=cyl,y=mpg)) +
geom_point()  +
scale_x_discrete(labels(breaks=c("4","6","8"), labels=c("test","6","8")))
p
p<-ggplot(data=mtcars,aes(x=cyl,y=mpg)) +
geom_point()  +
scale_x_discrete(labels(breaks=c("4","6","8"), labels=c("test","6","8")))
p<-ggplot(data=mtcars,aes(x=cyl,y=mpg)) +
geom_point()  +
scale_x_discrete(labels(breaks=c("4","6","8"), labels=c("mph 4","6","8")))
p<-ggplot(data=mtcars,aes(x=cyl,y=mpg)) +
geom_point()  +
scale_x_discrete(labels(breaks=c("4","6","8"), labels=c("4","6","8")))
p<-ggplot(data=mtcars,aes(x=cyl,y=mpg)) +
geom_point()  +
scale_x_discrete(labels(breaks=c("4","6","8"), labels=c("test","6","8")))
p
p<-ggplot(data=mtcars,aes(x=cyl,y=mpg))
p
geom_point()  +
scale_x_discrete(labels(breaks=c("4","6","8"), labels=c("4","6","8")))
geom_point()  +
p<-ggplot(data=mtcars,aes(x=cyl,y=mpg)) +
geom_point()  +
scale_x_discrete(labels(breaks=c("4","6","8"), labels=c("4","6","8")))
p<-ggplot(data=mtcars,aes(x=cyl,y=mpg)) +
geom_point()  +
scale_x_discrete(breaks=c("4","6","8"), labels=c("4","6","8"))
p<-ggplot(data=mtcars,aes(x=cyl,y=mpg)) +
geom_point()  +
scale_x_discrete(breaks=c("4","6","8"), labels=c("4","6","8"))
p
mtcars$cyl<-as.factor(mtcars$cyl)
p<-ggplot(data=mtcars,aes(x=cyl,y=mpg)) +
geom_point()  +
scale_x_discrete(breaks=c("4","6","8"), labels=c("4","6","8"))
p
p<-ggplot(data=mtcars,aes(x=cyl,y=mpg)) +
geom_point()  +
scale_x_discrete(breaks=c("4","6","8"), labels=c("test","6","8"))
p
p<-ggplot(data=mtcars,aes(x=cyl,y=mpg)) +
geom_point()  +
scale_x_discrete(breaks=c("4","6","8"), labels=c("test"))
p<-ggplot(data=mtcars,aes(x=cyl,y=mpg)) +
geom_point()  +
scale_x_discrete(breaks=c("4","8"), labels=c("test","test2"))
p
library(curl)
library(RJSONIO)
library(boxr)
library(httr)
library(jsonlite)
library(dplyr)
library(readxl)
library(stringr)
box_auth()
?box_auth
box_fresh_auth()
library(httr)
library(httpuv)
require(jsonlite)
oauth_endpoints("github")
?oauth_app()
oauth_endpoints("bitbucket")
oauth_endpoints("Atlassian")
oauth_endpoints("atlassian")
oauth_endpoints("Bitbucket")
oauth_endpoints("github")
oauth_endpoints("bitbucket")
oauth_endpoints("bitbucket.org")
install.packages('igraph')
install.packages('visNetwork')
install.packages("RMySQL","RPostgresSQL","RSQLite","tidyverse")
install.packages("RMySQL","RSQLite","tidyverse")
install.packages("tidyverse")
install.packages("jsonlite")
install.packages("XML")
install.packages("data.table")
install.packages("parallel")
install.packages("caret")
install.packages("faraway")
install.packages("mice")
install.packages("rinno")
install.packages("RInno")
install.packages("leaflet")
install.packages("dygraphs")
install.packages("rgl")
install.packages("seqinr")
pkg<-c("AppliedPredictiveModeling",
"caret",
"ElemStatLearn",
"pgmm",
"rpart",
"gbm",
"lubridate",
"forecast",
"e1071",
"dplyr",
"randomForest",
"rattle",
"foreach",
"doParallel")
install.packages(pkg)
pkg<-c("AppliedPredictiveModeling",
"caret",
"ElemStatLearn",
"pgmm",
"rpart",
"gbm",
"lubridate",
"forecast",
"e1071",
"dplyr",
"randomForest",
"rattle",
"foreach",
"doParallel")
pkg_load <- lapply(pkg, require, character.only = T, quietly = TRUE)
set.seed(123)
setwd("C:/Users/rballard/Desktop/Personal/Data Science Certification/08 pml/courseproj_jan18")
pkg<-c("AppliedPredictiveModeling",
"caret",
"ElemStatLearn",
"pgmm",
"rpart",
"gbm",
"lubridate",
"forecast",
"e1071",
"dplyr",
"randomForest",
"rattle",
"foreach",
"doParallel")
pkg_load <- lapply(pkg, require, character.only = T, quietly = TRUE)
set.seed(123)
setwd("C:/Users/rballard/Desktop/Personal/Data Science Certification/08 pml/courseproj_jan18")
#Instantiate set addresses
#trainloc <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
#testloc <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainloc <-"pml-training.csv"
testloc <-"pml-testing.csv"
#Reads in training and testing datasets
trainingData <- read.csv(file=paste(trainloc), header = TRUE, na.strings = c("NA", ""), stringsAsFactors=FALSE, row.names="X")
testingData <- read.csv(file=paste(testloc), header = TRUE, na.strings = c("NA", ""), stringsAsFactors=FALSE, row.names="X")
testingData
#Keep only complete records in training and testing datasets
trainingData<-trainingData[colSums(is.na(trainingData))==0]
testingData<-testingData[colSums(is.na(testingData))==0]
#Converts timestamp to datetime format
#trainingData$cvtd_timestamp.frmt<-dmy_hm(trainingData$cvtd_timestamp)
#testingData$cvtd_timestamp.frmt<-dmy_hm(testingData$cvtd_timestamp)
trainingData$classe <-as.factor(trainingData$classe)
#The first 7 columns of the datasets are ID columns and not used in predicting classe, so are removed
ids<-seq(1:6)
idfields<-names(trainingData)[ids]
trainingData<-trainingData[,-which(names(trainingData) %in% idfields)]
testingData<-testingData[,-which(names(testingData) %in% idfields)]
dim(trainingData)
#Partitions Training set to Training/Validation sets for cross-validation
inTrain <-createDataPartition(y=trainingData$classe,p=.7,list=FALSE)
trainingSet<-trainingData[inTrain,]
validationSet<-trainingData[-inTrain,]
#Detects number of cores and registers parallel backend
detectCores()
getDoParWorkers()
registerDoParallel(cores = 4)
control <-trainControl(method = "cv", number = 5)
rpart_fit<-train(classe ~ .,
data = trainingSet,
method = "rpart",
trControl = control)
print(rpart_fit, digits = 4)
fancyRpartPlot(rpart_fit$finalModel)
rpart_predict <- predict(rpart_fit, validationSet)
conf_rpart<-confusionMatrix(validationSet$classe,rpart_predict)
rf_fit<-train(classe~.,data = trainingSet,method="rf",
trControl = control)
print(rf_fit, digits = 4)
conf_rpart
rf_predict<-predict(testingData,rf_fit)
rf_predict<-predict(testingData$classe,rf_fit)
rf_predict<-predict(rf_fit,testingData)
rf_predict
testConfusMatrix <- confusionMatrix(testingData$classe, rf_predict)
testingData$classe
pkg<-c("AppliedPredictiveModeling",
"caret",
"ElemStatLearn",
"pgmm",
"rpart",
"gbm",
"lubridate",
"forecast",
"e1071",
"dplyr",
"randomForest",
"rattle",
"foreach",
"doParallel")
pkg_load <- lapply(pkg, require, character.only = T, quietly = TRUE)
set.seed(123)
setwd("C:/Users/rballard/Desktop/Personal/Data Science Certification/08 pml/courseproj_jan18")
#Instantiate set addresses
#trainloc <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
#testloc <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainloc <-"pml-training.csv"
testloc <-"pml-testing.csv"
#Reads in training and testing datasets
trainingData <- read.csv(file=paste(trainloc), header = TRUE, na.strings = c("NA", ""), stringsAsFactors=FALSE, row.names="X")
testingData <- read.csv(file=paste(testloc), header = TRUE, na.strings = c("NA", ""), stringsAsFactors=FALSE, row.names="X")
rf_fit<-train(classe~.,data = trainingSet,method="rf",
trControl = control)
pkg<-c("AppliedPredictiveModeling",
"caret",
"ElemStatLearn",
"pgmm",
"rpart",
"gbm",
"lubridate",
"forecast",
"e1071",
"dplyr",
"randomForest",
"rattle",
"foreach",
"doParallel")
pkg_load <- lapply(pkg, require, character.only = T, quietly = TRUE)
set.seed(123)
setwd("C:/Users/rballard/Desktop/Personal/Data Science Certification/08 pml/courseproj_jan18")
#Instantiate set addresses
#trainloc <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
#testloc <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainloc <-"pml-training.csv"
testloc <-"pml-testing.csv"
#Reads in training and testing datasets
trainingData <- read.csv(file=paste(trainloc), header = TRUE, na.strings = c("NA", ""), stringsAsFactors=FALSE, row.names="X")
testingData <- read.csv(file=paste(testloc), header = TRUE, na.strings = c("NA", ""), stringsAsFactors=FALSE, row.names="X")
names(trainingData)
head(trainingData,10)
str(trainingData)
table(trainingData$classe)
#Keep only complete records in training and testing datasets
trainingData<-trainingData[colSums(is.na(trainingData))==0]
testingData<-testingData[colSums(is.na(testingData))==0]
#Converts timestamp to datetime format
#trainingData$cvtd_timestamp.frmt<-dmy_hm(trainingData$cvtd_timestamp)
#testingData$cvtd_timestamp.frmt<-dmy_hm(testingData$cvtd_timestamp)
trainingData$classe <-as.factor(trainingData$classe)
#The first 7 columns of the datasets are ID columns and not used in predicting classe, so are removed
ids<-seq(1:6)
idfields<-names(trainingData)[ids]
trainingData<-trainingData[,-which(names(trainingData) %in% idfields)]
testingData<-testingData[,-which(names(testingData) %in% idfields)]
dim(trainingData)
#Detects number of cores and registers parallel backend
detectCores()
getDoParWorkers()
registerDoParallel(cores = 4)
#Sets cross validation
control <-trainControl(method = "cv", number = 5)
rpart_fit<-train(classe ~ .,
data = trainingSet,
method = "rpart",
trControl = control)
#Partitions Training set to Training/Validation sets for cross-validation
inTrain <-createDataPartition(y=trainingData$classe,p=.7,list=FALSE)
trainingSet<-trainingData[inTrain,]
validationSet<-trainingData[-inTrain,]
#Standardize naming conventions
testingSet<-trainingData
#Detects number of cores and registers parallel backend
detectCores()
getDoParWorkers()
registerDoParallel(cores = 4)
#Sets cross validation
control <-trainControl(method = "cv", number = 5)
rpart_fit<-train(classe ~ .,
data = trainingSet,
method = "rpart",
trControl = control)
print(rpart_fit, digits = 4)
fancyRpartPlot(rpart_fit$finalModel)
rpart_predict <- predict(rpart_fit, validationSet)
conf_rpart<-confusionMatrix(validationSet$classe,rpart_predict)
rf_fit<-train(classe~.,data = trainingSet,method="rf",
trControl = control)
print(rf_fit, digits = 4)
rf_predict<-predict(rf_fit,testingData)
testConfusMatrix <- confusionMatrix(testingData$classe, rf_predict)
testConfusMatrix
testConfusMatrix <- confusionMatrix(testingData$classe, rf_predict)
testingData$classe
rf_predict<-predict(rf_fit,testingData)
rf_predict
testingData
rf_fit<-train(classe~.,data = trainingSet,method="rf",
trControl = control)
print(rf_fit, digits = 4)
rf_predict<-predict(rf_fit,testingData)
testConfusMatrix <- confusionMatrix(validationSet$classe, rf_predict)
rf_predict<-predict(rf_fit,validationSet, type="class")
rf_predict<-predict(rf_fit,validationSet)
testConfusMatrix <- confusionMatrix(rf_predict,validationSet$classe)
testConfusMatrix$table
testConfusMatrix
prediction<-predict(rf_fit,testingSet)
prediction
testingData
#Standardize naming conventions
testingSet<-testingData
prediction<-predict(rf_fit,testingSet)
prediction
rpartConMat<-confusionMatrix(validationSet$classe,rpart_predict)
rpartConMat
#*****
install.packages('reticulate')
#*****
install.packages('NLTK')
#*****
install.packages('BeautifulSoup')
install.library("Contractions")
install.packages("Contractions")
install.packages(Contractions)
#*****
install.packages("NLP")
#*****
library(reticulate)
py_available()
path_to_python<-"C:\\Users\\rballard\\AppData\\Local\\Continuum\\anaconda3\\python"
use_python(path_to_python)
py_available()
py_config()
path_to_python<-"C:/Users/rballard/AppData/Local/Continuum/anaconda3/python"
use_python(path_to_python)
py_available()
py_config()
#*****
py_module_available("keras")
#*****
py_module_available("numpy")
pkg<-c("AppliedPredictiveModeling",
"caret",
"ElemStatLearn",
"pgmm",
"rpart",
"gbm",
"lubridate",
"forecast",
"e1071",
"dplyr",
"randomForest",
"rattle",
"foreach",
"doParallel")
pkg_load <- lapply(pkg, require, character.only = T, quietly = TRUE)
set.seed(123)
setwd("C:/Users/rballard/Desktop/Personal/Data Science Certification/08 pml/courseproj_jan18")
#Instantiate set addresses
#trainloc <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
#testloc <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainloc <-"pml-training.csv"
testloc <-"pml-testing.csv"
#Reads in training and testing datasets, keeps string valued fields
trainingData <- read.csv(file=paste(trainloc), header = TRUE, na.strings = c("NA", ""), stringsAsFactors=FALSE, row.names="X")
testingData <- read.csv(file=paste(testloc), header = TRUE, na.strings = c("NA", ""), stringsAsFactors=FALSE, row.names="X")
#Keep only complete records in training and testing datasets
trainingData<-trainingData[colSums(is.na(trainingData))==0]
testingData<-testingData[colSums(is.na(testingData))==0]
trainingData$classe <-as.factor(trainingData$classe)
#The first 7 columns of the datasets are ID columns and not used in predicting classe, so are removed
ids<-seq(1:6)
idfields<-names(trainingData)[ids]
trainingData<-trainingData[,-which(names(trainingData) %in% idfields)]
testingData<-testingData[,-which(names(testingData) %in% idfields)]
dim(trainingData)
#Partitions Training set to Training/Validation sets for cross-validation
inTrain <-createDataPartition(y=trainingData$classe,p=.7,list=FALSE)
trainingSet<-trainingData[inTrain,]
validationSet<-trainingData[-inTrain,]
#Standardize naming conventions
testingSet<-testingData
#Detects number of cores and registers parallel backend
detectCores()
getDoParWorkers()
registerDoParallel(cores = 4)
#Sets cross validation
control <-trainControl(method = "cv", number = 5)
rpart_fit<-train(classe ~ .,
data = trainingSet,
method = "rpart",
trControl = control)
print(rpart_fit, digits = 4)
fancyRpartPlot(rpart_fit$finalModel)
rpart_predict <- predict(rpart_fit, validationSet)
rpartConMat<-confusionMatrix(validationSet$classe,rpart_predict)
rf_fit<-train(classe~.,data = trainingSet,method="rf",
trControl = control)
print(rf_fit, digits = 4)
rf_predict<-predict(rf_fit,validationSet)
valConMat <- confusionMatrix(rf_predict,validationSet$classe)
valConMat
touch build_site.R
install.packages("rmarkdown")
setwd("C:/Users/rballard/Desktop/Personal/Data Science Certification/08 pml/courseproj_jan18")
touch _site.yml
library(rmarkdow)
library(rmarkdown)
touch _site.yml
#install.packages('devtools_1.13.2.tar.gz', lib="C:/Users/athompson/Documents/R/win-library/3.2",repos = NULL)
install.packages("devtools")
#install.packages('devtools_1.13.2.tar.gz', lib="C:/Users/athompson/Documents/R/win-library/3.2",repos = NULL)
install.packages("devtools")
install.packages("jsonlite")
install.packages("xlsx")
install.packages("tcltk2")
install.packages("haven")
install.packages("DBI")
install.packages("assertthat")
install.packages("magrittr")
install.packages("rJava")
install.packages("lubridate")
install.packages("zoo")
install.packages("dplyr")
install.packages("readxl")
install.packages("jsonlite")
install.packages("jsonlite")
install.packages("xlsx")
install.packages("tcltk2")
install.packages("haven")
install.packages("DBI")
install.packages("assertthat")
install.packages("magrittr")
install.packages("rJava")
install.packages("lubridate")
install.packages("zoo")
install.packages("dplyr")
install.packages("readxl")
install.packages("assertthat")
install.packages("assertthat")
install.packages("assertthat")
install.packages("assertthat")
install.packages("assertthat")
install.packages("magrittr")
install.packages("rJava")
install.packages("lubridate")
install.packages("zoo")
install.packages("dplyr")
install.packages("readxl")
