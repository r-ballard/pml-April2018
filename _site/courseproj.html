<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="R. Ballard" />

<meta name="date" content="2018-03-22" />

<title>PML Course Project</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>



<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="fluid-row" id="header">



<h1 class="title toc-ignore">PML Course Project</h1>
<h4 class="author"><em>R. Ballard</em></h4>
<h4 class="date"><em>March 22, 2018</em></h4>

</div>


<div id="section" class="section level1">
<h1></h1>
<div id="background" class="section level2">
<h2>Background</h2>
<p>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: <a href="http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har" class="uri">http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har</a> (see the section on the Weight Lifting Exercise Dataset).</p>
</div>
<div id="data" class="section level2">
<h2>Data</h2>
<p>The training data for this project are available here:</p>
<p><a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv" class="uri">https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv</a></p>
<p>The test data are available here:</p>
<p><a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv" class="uri">https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv</a></p>
<pre class="r"><code>setwd(&quot;C:/Users/rballard/Desktop/Personal/Data Science Certification/08 pml/courseproj_jan18&quot;)


#Instantiate set addresses
#trainloc &lt;- &quot;http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&quot;
#testloc &lt;- &quot;http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv&quot;
trainloc &lt;-&quot;pml-training.csv&quot;
testloc &lt;-&quot;pml-testing.csv&quot;

#Reads in training and testing datasets, keeps string valued fields
trainingData &lt;- read.csv(file=paste(trainloc), header = TRUE, na.strings = c(&quot;NA&quot;, &quot;&quot;), stringsAsFactors=FALSE, row.names=&quot;X&quot;)

testingData &lt;- read.csv(file=paste(testloc), header = TRUE, na.strings = c(&quot;NA&quot;, &quot;&quot;), stringsAsFactors=FALSE, row.names=&quot;X&quot;)</code></pre>
</div>
<div id="data-review-and-eda" class="section level2">
<h2>Data Review and EDA</h2>
<p>In this section the loaded datasets are reviewed. We check for missing values. It appears some of the fields have many missing values. In the next step these will be removed from the datasets. (This code chunk is not evaluated in HTML knit due to unwieldy output)</p>
<pre class="r"><code>names(trainingData)
head(trainingData,10)

str(trainingData)

table(trainingData$classe)
dim(trainingData)
dim(testingData)</code></pre>
</div>
<div id="cleanup-and-preprocessing" class="section level2">
<h2>Cleanup and Preprocessing</h2>
<p>In this phase identifier, timestamp, and fields containing NAs are removed from the dataset.</p>
<pre class="r"><code>#Keep only complete records in training and testing datasets
trainingData&lt;-trainingData[colSums(is.na(trainingData))==0]
testingData&lt;-testingData[colSums(is.na(testingData))==0]


trainingData$classe &lt;-as.factor(trainingData$classe)

#The first 7 columns of the datasets are ID columns and not used in predicting classe, so are removed
ids&lt;-seq(1:6)
idfields&lt;-names(trainingData)[ids]
trainingData&lt;-trainingData[,-which(names(trainingData) %in% idfields)]
testingData&lt;-testingData[,-which(names(testingData) %in% idfields)]</code></pre>
</div>
<div id="seperate-of-data-into-training-and-validation-sets" class="section level2">
<h2>Seperate of Data Into Training and Validation Sets</h2>
<p>This step seperates the training set into training (70% of training data) and validation (30% of training data) for cross-validation purposes.</p>
<pre class="r"><code>#Partitions Training set to Training/Validation sets for cross-validation
inTrain &lt;-createDataPartition(y=trainingData$classe,p=.7,list=FALSE)
trainingSet&lt;-trainingData[inTrain,]
validationSet&lt;-trainingData[-inTrain,]

#Standardize naming conventions
testingSet&lt;-testingData</code></pre>
</div>
<div id="rpart-classifcation-tree-model" class="section level2">
<h2>rpart Classifcation Tree Model</h2>
<p>Here we attempt to create a classificaiton model using recursive partitioning. The resulting confusion matrix indicates an accuracy of ~55%. The following section attempts to use the Random Forest method to increase accuracy.</p>
<pre class="r"><code>#Detects number of cores and registers parallel backend
detectCores()</code></pre>
<pre><code>## [1] 4</code></pre>
<pre class="r"><code>getDoParWorkers()</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r"><code>registerDoParallel(cores = 4)

#Sets cross validation
control &lt;-trainControl(method = &quot;cv&quot;, number = 5)
rpart_fit&lt;-train(classe ~ .,
                 data = trainingSet,
                 method = &quot;rpart&quot;,
                 trControl = control)

print(rpart_fit, digits = 4)</code></pre>
<pre><code>## CART 
## 
## 13737 samples
##    52 predictor
##     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 10989, 10991, 10989, 10990, 10989 
## Resampling results across tuning parameters:
## 
##   cp       Accuracy  Kappa 
##   0.02604  0.5622    0.4450
##   0.04307  0.4861    0.3349
##   0.11626  0.3326    0.0737
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was cp = 0.02604.</code></pre>
<pre class="r"><code>rpart_predict &lt;- predict(rpart_fit, validationSet)

rpartConMat&lt;-confusionMatrix(validationSet$classe,rpart_predict)</code></pre>
<pre class="r"><code>fancyRpartPlot(rpart_fit$finalModel)</code></pre>
<p><img src="courseproj_files/figure-html/RpartPlot-1.png" width="672" /></p>
</div>
</div>
<div id="random-forest-model" class="section level1">
<h1>Random Forest Model</h1>
<p>With the Random Forest model multiple bootstrap decision trees are generated and majority voting is enacted to create a model more accurate classification model at the cost of possible overfitting and less interperability by the reader. With K=5 crossfold validation the accuracy of our random forest model is 99.25%.</p>
<pre class="r"><code>rf_fit&lt;-train(classe~.,data = trainingSet,method=&quot;rf&quot;,
              trControl = control)

print(rf_fit, digits = 4)</code></pre>
<pre><code>## Random Forest 
## 
## 13737 samples
##    52 predictor
##     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 10990, 10989, 10991, 10989, 10989 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy  Kappa 
##    2    0.9900    0.9874
##   27    0.9912    0.9889
##   52    0.9856    0.9818
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 27.</code></pre>
<pre class="r"><code>rf_predict&lt;-predict(rf_fit,validationSet)
valConMat &lt;- confusionMatrix(rf_predict,validationSet$classe)

valConMat</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1672    7    0    0    0
##          B    2 1131    8    0    0
##          C    0    1 1015   19    2
##          D    0    0    3  944    1
##          E    0    0    0    1 1079
## 
## Overall Statistics
##                                         
##                Accuracy : 0.9925        
##                  95% CI : (0.99, 0.9946)
##     No Information Rate : 0.2845        
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16     
##                                         
##                   Kappa : 0.9905        
##  Mcnemar&#39;s Test P-Value : NA            
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9988   0.9930   0.9893   0.9793   0.9972
## Specificity            0.9983   0.9979   0.9955   0.9992   0.9998
## Pos Pred Value         0.9958   0.9912   0.9788   0.9958   0.9991
## Neg Pred Value         0.9995   0.9983   0.9977   0.9959   0.9994
## Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
## Detection Rate         0.2841   0.1922   0.1725   0.1604   0.1833
## Detection Prevalence   0.2853   0.1939   0.1762   0.1611   0.1835
## Balanced Accuracy      0.9986   0.9954   0.9924   0.9892   0.9985</code></pre>
<div id="test-set-predictions" class="section level2">
<h2>Test Set Predictions</h2>
<p>This is the random forest model classe prediction fit to the test set.</p>
<pre class="r"><code>prediction&lt;-predict(rf_fit,testingSet)
prediction</code></pre>
<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E</code></pre>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
